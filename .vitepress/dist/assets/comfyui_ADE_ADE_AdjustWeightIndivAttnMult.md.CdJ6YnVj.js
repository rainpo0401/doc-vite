import{_ as t,c as a,o as e,a4 as i}from"./chunks/framework.DpC1ZpOZ.js";const c=JSON.parse('{"title":"Documentation","description":"","frontmatter":{},"headers":[],"relativePath":"comfyui/ADE/ADE_AdjustWeightIndivAttnMult.md","filePath":"comfyui/ADE/ADE_AdjustWeightIndivAttnMult.md"}'),n={name:"comfyui/ADE/ADE_AdjustWeightIndivAttnMult.md"},l=i(`<h1 id="documentation" tabindex="-1">Documentation <a class="header-anchor" href="#documentation" aria-label="Permalink to &quot;Documentation&quot;">​</a></h1><ul><li>Class name: WeightAdjustIndivAttnMultNode</li><li>Category: Animate Diff 🎭🅐🅓/ad settings/weight adjust</li><li>Output node: False</li><li>Repo Ref: <a href="https://github.com/Kosinkadink/ComfyUI-AnimateDiff-Evolved.git" target="_blank" rel="noreferrer">https://github.com/Kosinkadink/ComfyUI-AnimateDiff-Evolved.git</a></li></ul><p>WeightAdjustIndivAttnMultNode 类旨在单独调整神经网络模型中注意力机制的权重。它允许通过将它们与指定的因子相乘来微调位置编码和注意力组件的影响。此节点对于通过调整注意力过程以满足特定任务需求来优化模型性能至关重要。</p><h1 id="input-types" tabindex="-1">Input types <a class="header-anchor" href="#input-types" aria-label="Permalink to &quot;Input types&quot;">​</a></h1><h2 id="required" tabindex="-1">Required <a class="header-anchor" href="#required" aria-label="Permalink to &quot;Required&quot;">​</a></h2><ul><li>pe_MULT <ul><li>pe_MULT 参数对于缩放位置编码权重至关重要。它直接影响模型捕获输入的顺序的能力，这对于语言翻译或文本生成等任务至关重要。</li><li>Comfy dtype: FLOAT</li><li>Python dtype: float</li></ul></li><li>attn_MULT <ul><li>attn_MULT 参数调整整体注意力权重，影响模型对输入序列不同部分的聚焦。这对于强调或淡化某些输入特征特别有用。</li><li>Comfy dtype: FLOAT</li><li>Python dtype: float</li></ul></li><li>attn_q_MULT <ul><li>attn_q_MULT 参数专门针对注意力机制中的查询权重，允许修改模型查询输入数据不同元素的方式。</li><li>Comfy dtype: FLOAT</li><li>Python dtype: float</li></ul></li><li>attn_k_MULT <ul><li>attn_k_MULT 参数影响注意力机制中的键权重，它决定了模型如何将输入序列与上下文对齐。</li><li>Comfy dtype: FLOAT</li><li>Python dtype: float</li></ul></li><li>attn_v_MULT <ul><li>attn_v_MULT 参数修改注意力机制中的值权重，这对于模型衡量不同输入元素的重要性至关重要。</li><li>Comfy dtype: FLOAT</li><li>Python dtype: float</li></ul></li><li>attn_out_weight_MULT <ul><li>attn_out_weight_MULT 参数缩放开了注意力机制的输出权重，这对于模型中输入序列的最终表示非常重要。</li><li>Comfy dtype: FLOAT</li><li>Python dtype: float</li></ul></li><li>attn_out_bias_MULT <ul><li>attn_out_bias_MULT 参数调整注意力机制输出的偏置项，这有助于微调模型的预测。</li><li>Comfy dtype: FLOAT</li><li>Python dtype: float</li></ul></li><li>other_MULT <ul><li>other_MULT 参数为模型中未明确分类的其他权重组件提供通用的缩放因子。</li><li>Comfy dtype: FLOAT</li><li>Python dtype: float</li></ul></li><li>print_adjustment <ul><li>print_adjustment 参数决定节点是否输出详细说明对权重所做的调整的日志。这对于调试和理解调整的影响非常有帮助。</li><li>Comfy dtype: BOOLEAN</li><li>Python dtype: bool</li></ul></li></ul><h2 id="optional" tabindex="-1">Optional <a class="header-anchor" href="#optional" aria-label="Permalink to &quot;Optional&quot;">​</a></h2><ul><li>prev_weight_adjust <ul><li>prev_weight_adjust 参数允许提供先前的权重调整组，使节点能够基于现有调整进行构建，或者重置并重新开始。</li><li>Comfy dtype: WEIGHT_ADJUST</li><li>Python dtype: Union[AdjustGroup, None]</li></ul></li></ul><h1 id="output-types" tabindex="-1">Output types <a class="header-anchor" href="#output-types" aria-label="Permalink to &quot;Output types&quot;">​</a></h1><ul><li>weight_adjust <ul><li>节点的输出是一个 WEIGHT_ADJUST 对象，它封装了对模型权重所做的调整。这个对象可以用来将这些调整应用于模型，或者在后续节点中进一步细化调整。</li><li>Comfy dtype: WEIGHT_ADJUST</li><li>Python dtype: AdjustGroup</li></ul></li></ul><h1 id="usage-tips" tabindex="-1">Usage tips <a class="header-anchor" href="#usage-tips" aria-label="Permalink to &quot;Usage tips&quot;">​</a></h1><ul><li>Infra type: CPU</li></ul><h1 id="source-code" tabindex="-1">Source code <a class="header-anchor" href="#source-code" aria-label="Permalink to &quot;Source code&quot;">​</a></h1><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>class WeightAdjustIndivAttnMultNode:</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    @classmethod</span></span>
<span class="line"><span>    def INPUT_TYPES(s):</span></span>
<span class="line"><span>        return {&#39;required&#39;: {&#39;pe_MULT&#39;: (&#39;FLOAT&#39;, {&#39;default&#39;: 1.0, &#39;min&#39;: 0.0, &#39;max&#39;: 2.0, &#39;step&#39;: 1e-06}), &#39;attn_MULT&#39;: (&#39;FLOAT&#39;, {&#39;default&#39;: 1.0, &#39;min&#39;: 0.0, &#39;max&#39;: 2.0, &#39;step&#39;: 1e-06}), &#39;attn_q_MULT&#39;: (&#39;FLOAT&#39;, {&#39;default&#39;: 1.0, &#39;min&#39;: 0.0, &#39;max&#39;: 2.0, &#39;step&#39;: 1e-06}), &#39;attn_k_MULT&#39;: (&#39;FLOAT&#39;, {&#39;default&#39;: 1.0, &#39;min&#39;: 0.0, &#39;max&#39;: 2.0, &#39;step&#39;: 1e-06}), &#39;attn_v_MULT&#39;: (&#39;FLOAT&#39;, {&#39;default&#39;: 1.0, &#39;min&#39;: 0.0, &#39;max&#39;: 2.0, &#39;step&#39;: 1e-06}), &#39;attn_out_weight_MULT&#39;: (&#39;FLOAT&#39;, {&#39;default&#39;: 1.0, &#39;min&#39;: 0.0, &#39;max&#39;: 2.0, &#39;step&#39;: 1e-06}), &#39;attn_out_bias_MULT&#39;: (&#39;FLOAT&#39;, {&#39;default&#39;: 1.0, &#39;min&#39;: 0.0, &#39;max&#39;: 2.0, &#39;step&#39;: 1e-06}), &#39;other_MULT&#39;: (&#39;FLOAT&#39;, {&#39;default&#39;: 1.0, &#39;min&#39;: 0.0, &#39;max&#39;: 2.0, &#39;step&#39;: 1e-06}), &#39;print_adjustment&#39;: (&#39;BOOLEAN&#39;, {&#39;default&#39;: False})}, &#39;optional&#39;: {&#39;prev_weight_adjust&#39;: (&#39;WEIGHT_ADJUST&#39;,)}}</span></span>
<span class="line"><span>    RETURN_TYPES = (&#39;WEIGHT_ADJUST&#39;,)</span></span>
<span class="line"><span>    CATEGORY = &#39;Animate Diff 🎭🅐🅓/ad settings/weight adjust&#39;</span></span>
<span class="line"><span>    FUNCTION = &#39;get_weight_adjust&#39;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    def get_weight_adjust(self, pe_MULT: float, attn_MULT: float, attn_q_MULT: float, attn_k_MULT: float, attn_v_MULT: float, attn_out_weight_MULT: float, attn_out_bias_MULT: float, other_MULT: float, print_adjustment: bool, prev_weight_adjust: AdjustGroup=None):</span></span>
<span class="line"><span>        if prev_weight_adjust is None:</span></span>
<span class="line"><span>            prev_weight_adjust = AdjustGroup()</span></span>
<span class="line"><span>        prev_weight_adjust = prev_weight_adjust.clone()</span></span>
<span class="line"><span>        adjust = AdjustWeight(pe_MULT=pe_MULT, attn_MULT=attn_MULT, attn_q_MULT=attn_q_MULT, attn_k_MULT=attn_k_MULT, attn_v_MULT=attn_v_MULT, attn_out_weight_MULT=attn_out_weight_MULT, attn_out_bias_MULT=attn_out_bias_MULT, other_MULT=other_MULT, print_adjustment=print_adjustment)</span></span>
<span class="line"><span>        prev_weight_adjust.add(adjust)</span></span>
<span class="line"><span>        return (prev_weight_adjust,)</span></span></code></pre></div>`,14),s=[l];function o(p,u,_,d,r,h){return e(),a("div",null,s)}const f=t(n,[["render",o]]);export{c as __pageData,f as default};
