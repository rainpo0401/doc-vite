import{_ as e,c as a,o as s,a4 as n}from"./chunks/framework.DpC1ZpOZ.js";const _=JSON.parse('{"title":"ACN_ReferencePreprocessor","description":"","frontmatter":{},"headers":[],"relativePath":"comfyui/ACN/ACN_ReferencePreprocessor.md","filePath":"comfyui/ACN/ACN_ReferencePreprocessor.md"}'),p={name:"comfyui/ACN/ACN_ReferencePreprocessor.md"},i=n(`<h1 id="acn-referencepreprocessor" tabindex="-1">ACN_ReferencePreprocessor <a class="header-anchor" href="#acn-referencepreprocessor" aria-label="Permalink to &quot;ACN_ReferencePreprocessor&quot;">â€‹</a></h1><ul><li>Class name: ReferencePreprocessorNode</li><li>Category: Adv-ControlNet ğŸ›‚ğŸ…ğŸ…’ğŸ…/Reference/preprocess</li><li>Output node: False</li><li>Repo Ref: <a href="https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git" target="_blank" rel="noreferrer">https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git</a></li></ul><p>ReferencePreprocessorNode æ—¨åœ¨ä½¿ç”¨å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸ºæ½œåœ¨ç©ºé—´è¡¨ç¤ºã€‚å®ƒåœ¨ä¸ºé«˜çº§æ§åˆ¶ç½‘ç»œæ“ä½œå‡†å¤‡å›¾åƒæ–¹é¢å‘æŒ¥ç€å…³é”®ä½œç”¨ï¼Œé€šè¿‡å°†è§†è§‰å†…å®¹ç¼–ç ä¸ºå¯ä»¥ç”±ä¸‹æ¸¸èŠ‚ç‚¹è¿›ä¸€æ­¥å¤„ç†çš„æ ¼å¼ã€‚</p><h1 id="input-types" tabindex="-1">Input types <a class="header-anchor" href="#input-types" aria-label="Permalink to &quot;Input types&quot;">â€‹</a></h1><h2 id="required" tabindex="-1">Required <a class="header-anchor" href="#required" aria-label="Permalink to &quot;Required&quot;">â€‹</a></h2><ul><li>image <ul><li>å›¾åƒå‚æ•°å¯¹äºèŠ‚ç‚¹çš„æ“ä½œè‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒæ˜¯éœ€è¦è¢«é¢„å¤„ç†çš„åŸå§‹è§†è§‰è¾“å…¥ã€‚å®ƒæ˜¯èŠ‚ç‚¹å°†è½¬æ¢ä¸ºæ½œåœ¨è¡¨ç¤ºçš„ä¸»è¦æ•°æ®ã€‚</li><li>Comfy dtype: IMAGE</li><li>Python dtype: torch.Tensor</li></ul></li><li>vae <ul><li>VAE å‚æ•°æŒ‡å®šäº†èŠ‚ç‚¹å°†ç”¨äºå°†å›¾åƒç¼–ç ä¸ºæ½œåœ¨ç©ºé—´çš„å˜åˆ†è‡ªç¼–ç å™¨æ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹æ˜¯èŠ‚ç‚¹åŠŸèƒ½çš„æ ¸å¿ƒï¼Œå› ä¸ºå®ƒå®šä¹‰äº†å›¾åƒå¦‚ä½•è¢«è½¬æ¢ã€‚</li><li>Comfy dtype: VAE</li><li>Python dtype: comfy.sd.VAE</li></ul></li><li>latent_size <ul><li>latent_size å‚æ•°å®šä¹‰äº†å›¾åƒå°†è¢«ç¼–ç çš„æ½œåœ¨ç©ºé—´çš„ç»´åº¦ã€‚å®ƒæ˜¯ä¸€ä¸ªå…³é”®ç»„ä»¶ï¼Œå› ä¸ºå®ƒå†³å®šäº†ç¼–ç è¡¨ç¤ºçš„è§„æ¨¡å’Œç»“æ„ã€‚</li><li>Comfy dtype: LATENT</li><li>Python dtype: Dict[str, Any]</li></ul></li></ul><h1 id="output-types" tabindex="-1">Output types <a class="header-anchor" href="#output-types" aria-label="Permalink to &quot;Output types&quot;">â€‹</a></h1><ul><li>proc_IMAGE <ul><li>proc_IMAGE è¾“å‡ºæ˜¯ä»¥æ½œåœ¨è¡¨ç¤ºå½¢å¼å¤„ç†åçš„å›¾åƒã€‚å®ƒå¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒä½œä¸ºæ§åˆ¶ç½‘ç»œä¸­åç»­èŠ‚ç‚¹çš„è¾“å…¥ï¼Œä½¿å¾—å¯ä»¥è¿›è¡Œæ›´é«˜çº§çš„å¤„ç†ã€‚</li><li>Comfy dtype: IMAGE</li><li>Python dtype: comfy.utils.ReferencePreprocWrapper</li></ul></li></ul><h1 id="usage-tips" tabindex="-1">Usage tips <a class="header-anchor" href="#usage-tips" aria-label="Permalink to &quot;Usage tips&quot;">â€‹</a></h1><ul><li>Infra type: GPU</li></ul><h1 id="source-code" tabindex="-1">Source code <a class="header-anchor" href="#source-code" aria-label="Permalink to &quot;Source code&quot;">â€‹</a></h1><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>class ReferencePreprocessorNode:</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    @classmethod</span></span>
<span class="line"><span>    def INPUT_TYPES(s):</span></span>
<span class="line"><span>        return {&#39;required&#39;: {&#39;image&#39;: (&#39;IMAGE&#39;,), &#39;vae&#39;: (&#39;VAE&#39;,), &#39;latent_size&#39;: (&#39;LATENT&#39;,)}}</span></span>
<span class="line"><span>    RETURN_TYPES = (&#39;IMAGE&#39;,)</span></span>
<span class="line"><span>    RETURN_NAMES = (&#39;proc_IMAGE&#39;,)</span></span>
<span class="line"><span>    FUNCTION = &#39;preprocess_images&#39;</span></span>
<span class="line"><span>    CATEGORY = &#39;Adv-ControlNet ğŸ›‚ğŸ…ğŸ…’ğŸ…/Reference/preprocess&#39;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    def preprocess_images(self, vae: VAE, image: Tensor, latent_size: Tensor):</span></span>
<span class="line"><span>        image = image.movedim(-1, 1)</span></span>
<span class="line"><span>        image = comfy.utils.common_upscale(image, latent_size[&#39;samples&#39;].shape[3] * 8, latent_size[&#39;samples&#39;].shape[2] * 8, &#39;nearest-exact&#39;, &#39;center&#39;)</span></span>
<span class="line"><span>        image = image.movedim(1, -1)</span></span>
<span class="line"><span>        try:</span></span>
<span class="line"><span>            image = vae.vae_encode_crop_pixels(image)</span></span>
<span class="line"><span>        except Exception:</span></span>
<span class="line"><span>            image = VAEEncode.vae_encode_crop_pixels(image)</span></span>
<span class="line"><span>        encoded = vae.encode(image[:, :, :, :3])</span></span>
<span class="line"><span>        return (ReferencePreprocWrapper(condhint=encoded),)</span></span></code></pre></div>`,12),r=[i];function l(t,o,c,d,u,h){return s(),a("div",null,r)}const f=e(p,[["render",l]]);export{_ as __pageData,f as default};
