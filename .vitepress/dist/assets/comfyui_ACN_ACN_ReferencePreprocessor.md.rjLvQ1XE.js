import{_ as e,c as a,o as s,a4 as n}from"./chunks/framework.DpC1ZpOZ.js";const _=JSON.parse('{"title":"ACN_ReferencePreprocessor","description":"","frontmatter":{},"headers":[],"relativePath":"comfyui/ACN/ACN_ReferencePreprocessor.md","filePath":"comfyui/ACN/ACN_ReferencePreprocessor.md"}'),p={name:"comfyui/ACN/ACN_ReferencePreprocessor.md"},i=n(`<h1 id="acn-referencepreprocessor" tabindex="-1">ACN_ReferencePreprocessor <a class="header-anchor" href="#acn-referencepreprocessor" aria-label="Permalink to &quot;ACN_ReferencePreprocessor&quot;">​</a></h1><ul><li>Class name: ReferencePreprocessorNode</li><li>Category: Adv-ControlNet 🛂🅐🅒🅝/Reference/preprocess</li><li>Output node: False</li><li>Repo Ref: <a href="https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git" target="_blank" rel="noreferrer">https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git</a></li></ul><p>ReferencePreprocessorNode 旨在使用变分自编码器（VAE）将输入图像转换为潜在空间表示。它在为高级控制网络操作准备图像方面发挥着关键作用，通过将视觉内容编码为可以由下游节点进一步处理的格式。</p><h1 id="input-types" tabindex="-1">Input types <a class="header-anchor" href="#input-types" aria-label="Permalink to &quot;Input types&quot;">​</a></h1><h2 id="required" tabindex="-1">Required <a class="header-anchor" href="#required" aria-label="Permalink to &quot;Required&quot;">​</a></h2><ul><li>image <ul><li>图像参数对于节点的操作至关重要，因为它是需要被预处理的原始视觉输入。它是节点将转换为潜在表示的主要数据。</li><li>Comfy dtype: IMAGE</li><li>Python dtype: torch.Tensor</li></ul></li><li>vae <ul><li>VAE 参数指定了节点将用于将图像编码为潜在空间的变分自编码器模型。这个模型是节点功能的核心，因为它定义了图像如何被转换。</li><li>Comfy dtype: VAE</li><li>Python dtype: comfy.sd.VAE</li></ul></li><li>latent_size <ul><li>latent_size 参数定义了图像将被编码的潜在空间的维度。它是一个关键组件，因为它决定了编码表示的规模和结构。</li><li>Comfy dtype: LATENT</li><li>Python dtype: Dict[str, Any]</li></ul></li></ul><h1 id="output-types" tabindex="-1">Output types <a class="header-anchor" href="#output-types" aria-label="Permalink to &quot;Output types&quot;">​</a></h1><ul><li>proc_IMAGE <ul><li>proc_IMAGE 输出是以潜在表示形式处理后的图像。它很重要，因为它作为控制网络中后续节点的输入，使得可以进行更高级的处理。</li><li>Comfy dtype: IMAGE</li><li>Python dtype: comfy.utils.ReferencePreprocWrapper</li></ul></li></ul><h1 id="usage-tips" tabindex="-1">Usage tips <a class="header-anchor" href="#usage-tips" aria-label="Permalink to &quot;Usage tips&quot;">​</a></h1><ul><li>Infra type: GPU</li></ul><h1 id="source-code" tabindex="-1">Source code <a class="header-anchor" href="#source-code" aria-label="Permalink to &quot;Source code&quot;">​</a></h1><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>class ReferencePreprocessorNode:</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    @classmethod</span></span>
<span class="line"><span>    def INPUT_TYPES(s):</span></span>
<span class="line"><span>        return {&#39;required&#39;: {&#39;image&#39;: (&#39;IMAGE&#39;,), &#39;vae&#39;: (&#39;VAE&#39;,), &#39;latent_size&#39;: (&#39;LATENT&#39;,)}}</span></span>
<span class="line"><span>    RETURN_TYPES = (&#39;IMAGE&#39;,)</span></span>
<span class="line"><span>    RETURN_NAMES = (&#39;proc_IMAGE&#39;,)</span></span>
<span class="line"><span>    FUNCTION = &#39;preprocess_images&#39;</span></span>
<span class="line"><span>    CATEGORY = &#39;Adv-ControlNet 🛂🅐🅒🅝/Reference/preprocess&#39;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    def preprocess_images(self, vae: VAE, image: Tensor, latent_size: Tensor):</span></span>
<span class="line"><span>        image = image.movedim(-1, 1)</span></span>
<span class="line"><span>        image = comfy.utils.common_upscale(image, latent_size[&#39;samples&#39;].shape[3] * 8, latent_size[&#39;samples&#39;].shape[2] * 8, &#39;nearest-exact&#39;, &#39;center&#39;)</span></span>
<span class="line"><span>        image = image.movedim(1, -1)</span></span>
<span class="line"><span>        try:</span></span>
<span class="line"><span>            image = vae.vae_encode_crop_pixels(image)</span></span>
<span class="line"><span>        except Exception:</span></span>
<span class="line"><span>            image = VAEEncode.vae_encode_crop_pixels(image)</span></span>
<span class="line"><span>        encoded = vae.encode(image[:, :, :, :3])</span></span>
<span class="line"><span>        return (ReferencePreprocWrapper(condhint=encoded),)</span></span></code></pre></div>`,12),r=[i];function l(t,o,c,d,u,h){return s(),a("div",null,r)}const f=e(p,[["render",l]]);export{_ as __pageData,f as default};
