import{_ as e,c as a,o as s,a4 as n}from"./chunks/framework.DpC1ZpOZ.js";const _=JSON.parse('{"title":"ACN_SparseCtrlRGBPreprocessor","description":"","frontmatter":{},"headers":[],"relativePath":"comfyui/ACN/ACN_SparseCtrlRGBPreprocessor.md","filePath":"comfyui/ACN/ACN_SparseCtrlRGBPreprocessor.md"}'),p={name:"comfyui/ACN/ACN_SparseCtrlRGBPreprocessor.md"},r=n(`<h1 id="acn-sparsectrlrgbpreprocessor" tabindex="-1">ACN_SparseCtrlRGBPreprocessor <a class="header-anchor" href="#acn-sparsectrlrgbpreprocessor" aria-label="Permalink to &quot;ACN_SparseCtrlRGBPreprocessor&quot;">​</a></h1><ul><li>Class name: RgbSparseCtrlPreprocessor</li><li>Category: Adv-ControlNet 🛂🅐🅒🅝/SparseCtrl/preprocess</li><li>Output node: False</li><li>Repo Ref: <a href="https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git" target="_blank" rel="noreferrer">https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git</a></li></ul><p>RgbSparseCtrlPreprocessor节点旨在为涉及稀疏控制机制的高级控制网络处理准备图像数据。它将输入图像放大以匹配潜在大小，将图像编码为潜在空间表示，并以特定于下游控制网络应用的预处理格式包装编码数据。</p><h1 id="input-types" tabindex="-1">Input types <a class="header-anchor" href="#input-types" aria-label="Permalink to &quot;Input types&quot;">​</a></h1><h2 id="required" tabindex="-1">Required <a class="header-anchor" href="#required" aria-label="Permalink to &quot;Required&quot;">​</a></h2><ul><li>image <ul><li>图像参数对于预处理阶段至关重要，因为它代表了将被放大和编码的原始输入。它是影响节点输出和控制网络中后续处理的基本元素。</li><li>Comfy dtype: IMAGE</li><li>Python dtype: torch.Tensor</li></ul></li><li>vae <ul><li>vae参数指定了变分自编码器（VAE）模型，该模型将用于将图像编码为潜在表示。这个模型对于节点将输入图像转换为适合高级控制网络操作的格式至关重要。</li><li>Comfy dtype: VAE</li><li>Python dtype: comfy.sd.VAE</li></ul></li><li>latent_size <ul><li>latent_size参数定义了图像将被编码的潜在空间的维度。它是节点输出质量的关键决定因素，以及编码数据在控制网络框架内的后续适用性。</li><li>Comfy dtype: LATENT</li><li>Python dtype: Dict[str, torch.Tensor]</li></ul></li></ul><h1 id="output-types" tabindex="-1">Output types <a class="header-anchor" href="#output-types" aria-label="Permalink to &quot;Output types&quot;">​</a></h1><ul><li>proc_IMAGE <ul><li>proc_IMAGE输出是输入图像的预处理版本，编码为潜在空间表示。此输出专门设计为与高级控制网络节点兼容，不打算用于其他类型的图像输入。</li><li>Comfy dtype: IMAGE</li><li>Python dtype: PreprocSparseRGBWrapper</li></ul></li></ul><h1 id="usage-tips" tabindex="-1">Usage tips <a class="header-anchor" href="#usage-tips" aria-label="Permalink to &quot;Usage tips&quot;">​</a></h1><ul><li>Infra type: GPU</li></ul><h1 id="source-code" tabindex="-1">Source code <a class="header-anchor" href="#source-code" aria-label="Permalink to &quot;Source code&quot;">​</a></h1><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>class RgbSparseCtrlPreprocessor:</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    @classmethod</span></span>
<span class="line"><span>    def INPUT_TYPES(s):</span></span>
<span class="line"><span>        return {&#39;required&#39;: {&#39;image&#39;: (&#39;IMAGE&#39;,), &#39;vae&#39;: (&#39;VAE&#39;,), &#39;latent_size&#39;: (&#39;LATENT&#39;,)}}</span></span>
<span class="line"><span>    RETURN_TYPES = (&#39;IMAGE&#39;,)</span></span>
<span class="line"><span>    RETURN_NAMES = (&#39;proc_IMAGE&#39;,)</span></span>
<span class="line"><span>    FUNCTION = &#39;preprocess_images&#39;</span></span>
<span class="line"><span>    CATEGORY = &#39;Adv-ControlNet 🛂🅐🅒🅝/SparseCtrl/preprocess&#39;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    def preprocess_images(self, vae: VAE, image: Tensor, latent_size: Tensor):</span></span>
<span class="line"><span>        image = image.movedim(-1, 1)</span></span>
<span class="line"><span>        image = comfy.utils.common_upscale(image, latent_size[&#39;samples&#39;].shape[3] * 8, latent_size[&#39;samples&#39;].shape[2] * 8, &#39;nearest-exact&#39;, &#39;center&#39;)</span></span>
<span class="line"><span>        image = image.movedim(1, -1)</span></span>
<span class="line"><span>        try:</span></span>
<span class="line"><span>            image = vae.vae_encode_crop_pixels(image)</span></span>
<span class="line"><span>        except Exception:</span></span>
<span class="line"><span>            image = VAEEncode.vae_encode_crop_pixels(image)</span></span>
<span class="line"><span>        encoded = vae.encode(image[:, :, :, :3])</span></span>
<span class="line"><span>        return (PreprocSparseRGBWrapper(condhint=encoded),)</span></span></code></pre></div>`,12),l=[r];function t(i,o,c,d,u,h){return s(),a("div",null,l)}const C=e(p,[["render",t]]);export{_ as __pageData,C as default};
